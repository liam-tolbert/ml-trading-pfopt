{
 "cells": [
  {
   "cell_type": "code",
   "id": "f0c666ef-f0d9-49cd-ba39-af137767330a",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.regime_switching.markov_regression import MarkovRegression\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt import risk_models\n",
    "from pypfopt import expected_returns\n",
    "import indicators\n",
    "import importlib\n",
    "importlib.reload(indicators)\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from collections import OrderedDict"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a30b8c33",
   "metadata": {},
   "source": [
    "stocks = [\n",
    "    \"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"META\", \"TSLA\", \"NVDA\", \"NFLX\", \"AMD\", \"INTC\",\n",
    "    \"JPM\", \"GS\", \"BAC\", \"C\", \"WFC\", \"V\", \"MA\", \"AXP\", \"BRK-B\",\n",
    "    \"UNH\", \"JNJ\", \"PFE\", \"LLY\", \"ABBV\", \"TMO\", \"DHR\", \"BMY\", \"GILD\",\n",
    "    \"XOM\", \"CVX\", \"COP\", \"OXY\", \"SLB\", \"HAL\", \"BP\", \"SHEL\", \"EOG\",\n",
    "    \"WMT\", \"COST\", \"HD\", \"LOW\", \"MCD\", \"SBUX\", \"TGT\", \"NKE\", \"PG\", \"KO\"\n",
    "]\n",
    "# Alternatively, use stocks2 if you want to\n",
    "stocks2 = [\n",
    "    \"ADBE\", \"CRM\", \"ORCL\", \"SAP\", \"NOW\", \"SHOP\", \"SQ\", \"ZM\", \"CRWD\", \"DDOG\",\n",
    "    \"TXN\", \"QCOM\", \"AVGO\", \"MU\", \"LRCX\", \"KLAC\", \"NXPI\", \"ADI\", \"MRVL\", \"SWKS\",\n",
    "    \"PYPL\", \"INTU\", \"FISV\", \"ADP\", \"VEEV\", \"TEAM\", \"WDAY\", \"ZS\", \"OKTA\", \"MDB\",\n",
    "    \"T\", \"VZ\", \"TMUS\", \"CHTR\", \"CMCSA\", \"DIS\", \"ROKU\", \"LYV\", \"TTWO\", \"ATVI\",\n",
    "    \"PEP\", \"KMB\", \"CL\", \"HSY\", \"MDLZ\", \"GIS\", \"MO\", \"PM\", \"EL\", \"STZ\"\n",
    "]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bc2bd7b3d7001517",
   "metadata": {},
   "source": [
    "# Uncomment this and/or the next cell if you want to refresh the dataset(s)\n",
    "#x = yf.download(stocks, start=\"2015-01-01\", end=\"2025-04-15\", interval=\"1wk\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ba74d74e0fa06f41",
   "metadata": {},
   "source": [
    "#y = yf.download(\"^GSPC\", start=\"2010-01-01\", end=\"2025-04-15\", interval=\"1wk\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4f0166c29b0c3b63",
   "metadata": {},
   "source": [
    "def extract_ticker_dataframe(csv_filepath: str, ticker: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads a multi-ticker CSV file (like one from yfinance) and isolates the data\n",
    "    for the specified ticker. This updated version assumes that the CSV contains the\n",
    "    dates as the index (first column), so we use that as the Date information.\n",
    "\n",
    "    The CSV is expected to have a two-row header:\n",
    "      - The first row contains field names (e.g., \"Open\", \"High\", etc.).\n",
    "      - The second row contains the ticker symbols for each column.\n",
    "\n",
    "    The returned DataFrame's columns will be ordered as needed for Backtrader:\n",
    "      Date, Open, High, Low, Close, Volume.\n",
    "    \"\"\"\n",
    "    # Use the first column as the index so that the dates are read from the CSV.\n",
    "    df = pd.read_csv(csv_filepath)#, header=[0, 1], index_col=0)\n",
    "\n",
    "    # Convert the index to datetime in case it's not already\n",
    "    df.index = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "    df = df.drop(\"Date\", axis=1)\n",
    "\n",
    "    # Identify all columns for the specified ticker (matching on the lower level).\n",
    "    ticker_cols = [col for col in df.columns if ticker == str(col).strip().split(\"_\")[-1]]\n",
    "    if not ticker_cols:\n",
    "        raise ValueError(f\"Ticker '{ticker}' not found in the CSV file.\")\n",
    "\n",
    "    # Extract the ticker's columns\n",
    "    df_ticker = df.loc[:, ticker_cols].copy()\n",
    "    #df_ticker.columns = [col[0].strip() for col in df_ticker.columns]\n",
    "\n",
    "    # Removing ticker name from column names\n",
    "    for col in df_ticker.columns:\n",
    "        df_ticker.rename(columns={col: str(col).split(\"_\")[0]}, inplace=True)\n",
    "\n",
    "    # Rearranging the columns according to Backtrader's expected order.\n",
    "    desired_order = [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "\n",
    "    available_order = [col for col in desired_order if col in df_ticker.columns]\n",
    "    df_ticker = df_ticker[available_order]\n",
    "\n",
    "    # If desired, reset the index (which contains the Date) back to a column.\n",
    "    df_ticker = df_ticker.reset_index().rename(columns={\"index\": \"Date\"}).set_index(\"Date\")\n",
    "\n",
    "    return df_ticker"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "20041a3b4c31a1ba",
   "metadata": {},
   "source": [
    "# If you uncommented the yf.download cells, uncomment these as well. One is for the stocks and the other is for the sp500\n",
    "'''\n",
    "stockData = x.copy()\n",
    "\n",
    "# Rename columns, joining multi-level column names into a single string with \"_\".\n",
    "stockData.columns = [\"_\".join(col) if isinstance(col, tuple) else col for col in stockData.columns]\n",
    "\n",
    "# Remove unnecessary columns such as \"level_0\" or \"index\" that may have been carried over.\n",
    "stockData = stockData.loc[:, ~stockData.columns.isin([\"level_0\", \"index\"])]\n",
    "stockData.to_csv(\"50stocks.csv\")\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "sp500 = y.copy()\n",
    "\n",
    "sp500.columns = [\"_\".join(col) if isinstance(col, tuple) else col for col in sp500.columns]\n",
    "\n",
    "sp500 = sp500.loc[:, ~sp500.columns.isin([\"level_0\", \"index\"])]\n",
    "sp500.to_csv(\"SP500.csv\")'''"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "02b3d74d-2b42-4d24-ac2f-787adac5c64c",
   "metadata": {},
   "source": [
    "# 1. Feature engineering: Hamilton Regime Switching Model\n",
    "sp500 = pd.read_csv(\"SP500.csv\")\n",
    "sp500.set_index(\"Date\", inplace=True)\n",
    "sp500.index = pd.to_datetime(sp500.index)\n",
    "sp500['Log_Returns'] = np.log(sp500['Close_^GSPC'] / sp500['Close_^GSPC'].shift(1))\n",
    "sp500 = sp500.dropna()\n",
    "\n",
    "def classify_regimes(sp500):\n",
    "    model = MarkovRegression(sp500['Log_Returns'], k_regimes=2, trend='c', switching_variance=True)\n",
    "    result = model.fit()\n",
    "    #print(result.summary())\n",
    "    smoothed_probs = result.smoothed_marginal_probabilities\n",
    "    sp500['Regime'] = smoothed_probs.idxmax(axis=1)\n",
    "    sp500['Bull_Prob'] = smoothed_probs[0]\n",
    "\n",
    "    \"\"\"if show_regimes:\n",
    "        plt.plot(sp500.index, smoothed_probs[0], label=\"Probability of Bull Market\")\n",
    "        plt.fill_between(sp500.index, 0, 1, where=sp500['Bull_Prob'] > 0.5, color='green', alpha=0.3)\n",
    "        plt.fill_between(sp500.index, 0, 1, where=sp500['Bull_Prob'] <= 0.5, color='red', alpha=0.3)\n",
    "        plt.legend()\n",
    "        plt.title(\"Bull vs. Bear Market Probability\")\n",
    "        plt.show()\"\"\"\n",
    "\n",
    "    return sp500[\"Bull_Prob\"].to_frame()\n",
    "    # 0 -> Bull, 1 -> Bear\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5ab565fc88c678dc",
   "metadata": {},
   "source": [
    "# Compute rolling portfolio weights using a lookback period (e.g., 52 weeks)\n",
    "def compute_rolling_portfolio_weights(data, lookback_window=52):\n",
    "    \"\"\"\n",
    "    Computes portfolio weights for each date using historical data up to that date.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): DataFrame with dates as index and stocks as columns.\n",
    "        lookback_window (int): Number of days to look back for the optimization.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with dates as index and stocks as columns, containing weights.\n",
    "    \"\"\"\n",
    "    weights_list = []\n",
    "    dates = []\n",
    "    for date in data.index[lookback_window:]:\n",
    "        window_data = data.loc[:date].tail(lookback_window)\n",
    "        mu = expected_returns.mean_historical_return(window_data)\n",
    "        S = risk_models.sample_cov(window_data)\n",
    "        ef = EfficientFrontier(mu, S)\n",
    "        try:\n",
    "            ef.max_sharpe()\n",
    "            clean_weights = ef.clean_weights()\n",
    "        except Exception as e:\n",
    "            # In case optimization fails, assign zero weights.\n",
    "            clean_weights = {stock: 0 for stock in data.columns}\n",
    "        weights_list.append(clean_weights)\n",
    "        dates.append(date)\n",
    "    weights_df = pd.DataFrame(weights_list, index=dates)\n",
    "    return weights_df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "24a7cf2f-ba18-4c0b-9d54-b241ce9e87b1",
   "metadata": {},
   "source": [
    "# 2. Feature engineering: Technical indicators, fundamentals\n",
    "# SMA, RSI, MACD, etc. etc. basically, seeing which indicator sticks\n",
    "def create_stock_features(stocks, stock_data_filename):\n",
    "    feature_rows = []\n",
    "    regime_df = classify_regimes(sp500)\n",
    "\n",
    "    for stock in stocks:\n",
    "        # will be filled with indicators for one stock\n",
    "        prices = extract_ticker_dataframe(stock_data_filename, stock)\n",
    "        # weekly return\n",
    "        prices[\"Return\"] = prices[\"Close\"].pct_change(periods=2)\n",
    "\n",
    "        features = pd.DataFrame(index=prices.index)\n",
    "\n",
    "        # Simple Moving Avg Comparison (5 vs 20)\n",
    "        sma = indicators.sma_strategy(prices[\"Close\"].to_frame(), 5, 20)\n",
    "        features[\"SMA_5v20\"] = sma[\"signal_raw\"]\n",
    "\n",
    "        # Relative Strength Index (RSI)\n",
    "        rsi = indicators.rsi_strategy(prices[\"Close\"].to_frame())\n",
    "        features[\"RSI\"] = rsi[\"rsi\"]\n",
    "\n",
    "        # Moving Average Convergence Divergence (MACD)\n",
    "        macd = indicators.macd_strategy(prices[\"Close\"].to_frame())\n",
    "        features[\"MACD\"] = macd[\"signal_raw\"] # only using signal, not other columns, since I don't want to have weird \"fitting\" of the model to the components of the macd signal\n",
    "\n",
    "        # Bollinger Bands\n",
    "        bands = indicators.bollinger_strategy(prices[\"Close\"].to_frame())\n",
    "        features[\"Bollinger_Bands\"] = bands[\"signal_ternary\"]\n",
    "\n",
    "        # Average True Range (ATR)\n",
    "        atr = indicators.atr_indicator(prices[[\"High\", \"Low\", \"Close\"]])\n",
    "        features[\"ATR\"] = atr[\"signal\"]\n",
    "\n",
    "        # Stochastic Oscillator Strategy\n",
    "        stochastic = indicators.stochastic_strategy(prices[[\"High\", \"Low\", \"Close\"]])\n",
    "        features[\"Stochastic\"] = stochastic[\"signal\"]\n",
    "\n",
    "        # OBV (On-Balance Volume)\n",
    "        obv = indicators.obv_strategy(prices[[\"Close\", \"Volume\"]])\n",
    "        features[\"OBV\"] = obv[\"obv\"]\n",
    "\n",
    "        # ADX (Average Directional Index)\n",
    "        adx = indicators.adx_strategy(prices[[\"High\", \"Low\", \"Close\"]])\n",
    "        features[\"ADX\"] = adx[\"adx\"]\n",
    "\n",
    "        # Aroon Indicator\n",
    "        aroon = indicators.aroon_strategy(prices[[\"High\", \"Low\"]])\n",
    "        features[\"Aroon\"] = aroon[\"aroon_oscillator\"]\n",
    "\n",
    "        # Returns features. Overall 4 week percent change, split into 3 week period, 1 week lag and 1 week period, 0 week lag\n",
    "        features[\"Returns-3wk-1wklag\"] = prices[\"Close\"].shift(1).pct_change(periods=3)\n",
    "        features[\"Returns-1wk-0wklag\"] = prices[\"Close\"].pct_change()\n",
    "\n",
    "        # Other technical indicators and fundamentals?\n",
    "\n",
    "        # rolling return (2 week window)\n",
    "        features[\"Returns-2wk\"] = prices[\"Return\"]\n",
    "        features[\"Bull_Probability\"] = regime_df[\"Bull_Prob\"]\n",
    "\n",
    "        features[\"Stock\"] = stock\n",
    "        features = features.reset_index().rename(columns={\"index\": \"Date\"})\n",
    "        feature_rows.append(features)\n",
    "\n",
    "    # Combine data for all stocks into one dataframe\n",
    "    features_long = pd.concat(feature_rows, ignore_index=True).set_index(\"Date\").dropna()\n",
    "\n",
    "\n",
    "\n",
    "    return features_long\n",
    "\n",
    "df = create_stock_features(stocks, \"50stocks.csv\")\n",
    "df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "548eac63-4026-4551-b895-c9bf5d8afad3",
   "metadata": {},
   "source": [
    "def label_signal(return_val, buy_thresh=0.01, sell_thresh=-0.01):\n",
    "    if return_val > buy_thresh:\n",
    "        return 0\n",
    "    elif return_val < sell_thresh:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "df['Signal'] = df['Returns-2wk'].apply(label_signal)\n",
    "\n",
    "# Sort by date?\n",
    "df = df.sort_values(by='Date')\n",
    "\n",
    "# 70% train, 15% val, 15% test\n",
    "split_1 = int(len(df) * 0.7)\n",
    "split_2 = int(len(df) * 0.85)\n",
    "\n",
    "train = df.iloc[:split_1]\n",
    "val = df.iloc[split_1:split_2]\n",
    "test = df.iloc[split_2:]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "506d55c6e3883b90",
   "metadata": {},
   "source": [
    "features = [\"SMA_5v20\", \"RSI\", \"MACD\", \"Bollinger_Bands\", \"ATR\", \"Stochastic\", \"OBV\", \"ADX\", \"Aroon\", \"Bull_Probability\", \"Returns-3wk-1wklag\", \"Returns-1wk-0wklag\"]\n",
    "X_train = train[features]\n",
    "y_train = train['Signal']\n",
    "X_val = val[features]\n",
    "y_val = val['Signal']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ce26651914db3c39",
   "metadata": {},
   "source": [
    "# tuning class weights b/c the val set has underrepresented sell orders\n",
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "class_weight_dict = dict(zip(classes, class_weights))\n",
    "print(\"Class Weights:\", class_weight_dict)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bc9d2abab23b464f",
   "metadata": {},
   "source": [
    "# Map class weights to each sample in training set\n",
    "sample_weights = y_train.map(class_weight_dict)\n",
    "\n",
    "# Train the model\n",
    "model = XGBClassifier(\n",
    "    objective='multi:softprob',  # for multi-class\n",
    "    num_class=len(classes),\n",
    "    eval_metric='mlogloss',\n",
    "    use_label_encoder=False,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, sample_weight=sample_weights)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "99a4656647843b55",
   "metadata": {},
   "source": [
    "X_test = test[features]\n",
    "y_test = test['Signal']\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1d8d21882d807b03",
   "metadata": {},
   "source": [
    "# NOW do portfolio weight stuff with y_pred... AFTER your tuning for val and using the test set please :)\n",
    "today_stocks_features = df.tail(len(stocks))\n",
    "todays_pred = model.predict(today_stocks_features[features])\n",
    "stock_col = today_stocks_features[\"Stock\"].reset_index().drop(columns=\"Date\")\n",
    "pred_col = pd.DataFrame(todays_pred)\n",
    "\n",
    "# Making recommendations per stock\n",
    "recommendations = stock_col.join(pred_col)\n",
    "recommendations.columns = [\"Stock\", \"Recommendation\"]\n",
    "recommendations[\"Recommendation\"] = recommendations[\"Recommendation\"].map({0: 'Hold', 1: 'Buy', 2: 'Sell'})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ed2f42abd33d8229",
   "metadata": {},
   "source": [
    "# Isolating buys\n",
    "buy_recommendations = recommendations[recommendations.Recommendation == \"Buy\"].drop(columns=\"Recommendation\")\n",
    "rec_array = buy_recommendations.to_numpy().flatten().tolist()\n",
    "buy_stocks_history = extract_ticker_dataframe(\"50stocks.csv\", rec_array[0])[\"Close\"]\n",
    "for i in range(1, len(rec_array)):\n",
    "    a = extract_ticker_dataframe(\"50stocks.csv\", rec_array[i])[\"Close\"]\n",
    "    buy_stocks_history = pd.concat([buy_stocks_history, a], axis=1, join='inner')\n",
    "buy_stocks_history.columns = rec_array"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a092b9a3",
   "metadata": {},
   "source": [
    "def compute_adjusted_mu(buy_probs, baseline_mu, alpha=0.01):\n",
    "    tickers = baseline_mu.index.intersection(buy_probs.index)\n",
    "    adjusted_mu = baseline_mu.loc[tickers] * (1 + alpha * (buy_probs.loc[tickers] - 0.5))\n",
    "    return adjusted_mu\n",
    "\n",
    "probs = model.predict_proba(today_stocks_features[features])\n",
    "probs_db = pd.DataFrame(probs, columns=[\"Hold\", \"Buy\", \"Sell\"], index=today_stocks_features[\"Stock\"].values)\n",
    "buy_probs = probs_db[\"Buy\"]\n",
    "\n",
    "# 2. Compute the baseline mu\n",
    "baseline_mu = expected_returns.mean_historical_return(buy_stocks_history)\n",
    "\n",
    "# 3. Compute the adjusted mu. Alpha is a strength parameter for the adjustment. Larger values will make the adjustment more aggressive.\n",
    "adjusted_mu = compute_adjusted_mu(buy_probs, baseline_mu, alpha=0.05)\n",
    "\n",
    "S = risk_models.sample_cov(buy_stocks_history)\n",
    "\n",
    "# Ensure that the adjusted_mu and S use the same tickers\n",
    "common_tickers = adjusted_mu.index.intersection(S.index)\n",
    "\n",
    "S = S.loc[common_tickers, common_tickers]\n",
    "ef = EfficientFrontier(adjusted_mu, S)\n",
    "ef.max_sharpe()\n",
    "clean_weights = ef.clean_weights()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5cbac468c0c6e74d",
   "metadata": {},
   "source": [
    "# Portfolio weights\n",
    "weights = OrderedDict()\n",
    "for key, value in clean_weights.items():\n",
    "    if value != 0.0:\n",
    "        weights[key] = value\n",
    "weights"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
